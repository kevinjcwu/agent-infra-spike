# Blueprint Pattern Implementation - Ready to Execute

**Date**: November 10, 2025
**Status**: âœ… APPROVED - Ready for implementation
**Approach**: Modular templates + Blueprint pattern

---

## What's Been Approved

âœ… **Blueprint Pattern Design** - 3 scenarios with graceful degradation
âœ… **Modular Template Architecture** - Composable infrastructure modules
âœ… **Implementation Plan Updated** - Includes template modularization
âœ… **Feature Request Tracking** - Data-driven prioritization

---

## Key Design Decisions

### **1. Modular Templates (Approved)**

```
capabilities/databricks/templates/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ resource_group.tf.j2      # Always needed
â”‚   â””â”€â”€ workspace.tf.j2            # Always needed
â”œâ”€â”€ compute/
â”‚   â”œâ”€â”€ instance_pool.tf.j2       # For pre-warmed compute
â”‚   â””â”€â”€ interactive_cluster.tf.j2 # For interactive/dev work
â””â”€â”€ supporting/
    â”œâ”€â”€ variables.tf.j2
    â”œâ”€â”€ outputs.tf.j2              # Dynamic based on resources
    â”œâ”€â”€ provider.tf.j2
    â””â”€â”€ terraform.tfvars.tf.j2
```

**Why**: Mix and match resources per blueprint (Lego block approach)

### **2. Blueprint Composition**

```python
Blueprint("databricks-ml-dev").resources = [
    "core/resource_group.tf.j2",
    "core/workspace.tf.j2",
    "compute/interactive_cluster.tf.j2"
]

Blueprint("databricks-ml-prod").resources = [
    "core/resource_group.tf.j2",
    "core/workspace.tf.j2",
    "compute/instance_pool.tf.j2"  # Different compute pattern
]
```

**Why**: Same modules, different combinations per use case

### **3. Three Scenarios**

- **Scenario 1**: Exact match â†’ Full automation
- **Scenario 2**: No match â†’ Graceful failure, show alternatives
- **Scenario 3**: Partial match â†’ Deploy what we can, guide manual steps

**Why**: User-friendly degradation, always offers value

---

## Implementation Phases

### **Phase 0: Template Modularization** (NEW)
- Split monolithic `main.tf.j2` into modules
- Update `TerraformGenerator` for composition
- Backward compatibility maintained

### **Phase 1: Data Structures**
- Blueprint models (name, resources, metadata)
- BlueprintMatch (matching result)
- FeatureRequest (tracking)

### **Phase 2: Core Logic**
- BlueprintMatcher (find best match)
- FeatureRequestTracker (log unsupported)
- Integration with DatabricksCapability

### **Phase 3: User Experience**
- Update response formatting
- Clear messages for each scenario
- Feature request visibility

### **Phase 4-6: Testing, Docs, Rollout**
- Comprehensive tests
- Documentation updates
- Release v0.3.0

---

## What Gets Built

### **New Files** (11 total)

```
capabilities/databricks/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ blueprints.py                      # NEW: Data models
â”œâ”€â”€ blueprints/
â”‚   â”œâ”€â”€ __init__.py                        # NEW
â”‚   â””â”€â”€ library.py                         # NEW: Blueprint definitions
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ blueprint_matcher.py               # NEW: Matching logic
â”‚   â””â”€â”€ feature_tracker.py                 # NEW: Request tracking
â””â”€â”€ templates/                             # NEW DIRECTORY
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ resource_group.tf.j2           # NEW: Split from main.tf.j2
    â”‚   â””â”€â”€ workspace.tf.j2                # NEW: Split from main.tf.j2
    â”œâ”€â”€ compute/
    â”‚   â”œâ”€â”€ instance_pool.tf.j2            # NEW: Extracted
    â”‚   â””â”€â”€ interactive_cluster.tf.j2      # NEW: Uncommented & extracted
    â””â”€â”€ supporting/
        â”œâ”€â”€ variables.tf.j2                # MOVED from /templates
        â”œâ”€â”€ outputs.tf.j2                  # MOVED + dynamic logic
        â”œâ”€â”€ provider.tf.j2                 # MOVED from /templates
        â””â”€â”€ terraform.tfvars.j2            # MOVED from /templates

tests/
â”œâ”€â”€ test_blueprint_pattern.py              # NEW: Unit tests
â””â”€â”€ test_blueprint_integration.py          # NEW: Integration tests
```

### **Modified Files** (4 total)

```
capabilities/databricks/
â”œâ”€â”€ capability.py                          # MODIFIED: Blueprint integration
â””â”€â”€ provisioning/terraform/
    â””â”€â”€ generator.py                       # MODIFIED: Modular composition

capabilities/base.py                       # MODIFIED: CapabilityPlan fields
orchestrator/orchestrator_agent.py         # MODIFIED: Response formatting
```

### **Removed/Deprecated Files** (1)

```
templates/                                 # DEPRECATED (move to capability)
â”œâ”€â”€ main.tf.j2                            # Will be split into modules
â”œâ”€â”€ variables.tf.j2                       # Move to supporting/
â”œâ”€â”€ outputs.tf.j2                         # Move to supporting/
â”œâ”€â”€ provider.tf.j2                        # Move to supporting/
â””â”€â”€ terraform.tfvars.j2                   # Move to supporting/
```

---

## Example: How It Works

### **User Request**
```
"I need Databricks for ML development with GPUs"
```

### **System Flow**
```
1. IntentParser â†’ workload_type="ml", enable_gpu=True

2. BlueprintMatcher â†’ Finds "databricks-ml-dev" (exact match)
   Resources: ["core/resource_group.tf.j2",
               "core/workspace.tf.j2",
               "compute/interactive_cluster.tf.j2"]

3. DecisionMaker â†’ instance_type="Standard_NC6s_v3" (GPU)

4. TerraformGenerator.generate_from_resources()
   - Read resource_group.tf.j2 â†’ render â†’ HCL block 1
   - Read workspace.tf.j2 â†’ render â†’ HCL block 2
   - Read interactive_cluster.tf.j2 â†’ render â†’ HCL block 3
   - Combine into main.tf
   - Generate dynamic outputs (workspace_url, cluster_id, etc.)

5. TerraformExecutor â†’ Deploy all 3 resources

6. Result: âœ… ML workspace with GPU cluster in 15 minutes
```

---

## Benefits

âœ… **Composability**: Mix and match infrastructure modules
âœ… **Maintainability**: Each module is small and focused
âœ… **Scalability**: Easy to add new blueprints (just list modules)
âœ… **User-Friendly**: Graceful degradation for unsupported cases
âœ… **Data-Driven**: Track requests to prioritize features
âœ… **Backward Compatible**: Existing tests keep working

---

## Timeline

**Estimated**: 3-4 days

- **Day 1**: Phase 0 (template modularization) + Phase 1 (data structures)
- **Day 2**: Phase 2 (integration) + Phase 3 (UX)
- **Day 3**: Phase 4 (testing) + Phase 5 (docs)
- **Day 4**: Buffer + rollout

---

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| Breaking existing functionality | Comprehensive test suite, backward compatibility |
| Template syntax errors | Validate each module independently |
| Blueprint matching failures | Extensive test scenarios |
| Feature tracking data loss | JSON validation, error handling |

---

## Success Criteria

- âœ… All 94 existing tests pass
- âœ… 20+ new tests added (unit + integration)
- âœ… All 3 scenarios work end-to-end
- âœ… Modular templates compose correctly
- âœ… Feature tracking persists
- âœ… Clear user messages for each scenario
- âœ… No breaking changes to existing deployments

---

## Next Step: Implementation

**Ready to proceed with implementation?**

The plan is complete, modular approach is designed, and all scenarios are covered.

**Start implementation**: Create feature branch and begin Phase 0 (template modularization)

---

## Questions Before Starting?

Review checklist:
- [ ] Modular template structure makes sense
- [ ] Blueprint composition approach is clear
- [ ] Three scenarios cover all cases
- [ ] Feature tracking approach is sufficient
- [ ] Testing strategy is comprehensive
- [ ] Timeline is reasonable

**If everything looks good, implementation can begin!** ðŸš€
