# Complete Visual Flow: User Query â†’ Deployed Infrastructure

**Last Updated**: November 10, 2025
**Status**: Current Implementation with November 10 Optimizations

---

## ðŸŽ¯ Complete End-to-End Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ‘¤ USER INPUT                                                                   â”‚
â”‚  "I want provision a databricks workspace for data analytics"                   â”‚
â”‚                                                                                  â”‚
â”‚  CLI: cli_maf.py captures input â†’ orchestrator.process_message()                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ¤– ORCHESTRATOR (MAF + Azure OpenAI GPT-4o)                                    â”‚
â”‚  File: orchestrator/orchestrator_agent.py                                       â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  STEP 1: Understand Intent & Select Capability                            â”‚ â”‚
â”‚  â”‚  LLM analyzes: "databricks workspace for data analytics"                  â”‚ â”‚
â”‚  â”‚  â†“                                                                         â”‚ â”‚
â”‚  â”‚  Calls Tool: select_capabilities(["provision_databricks"])                â”‚ â”‚
â”‚  â”‚     File: orchestrator/tools.py                                           â”‚ â”‚
â”‚  â”‚     â†“                                                                      â”‚ â”‚
â”‚  â”‚     Validates against CapabilityRegistry â†’ âœ… Valid                        â”‚ â”‚
â”‚  â”‚     File: orchestrator/capability_registry.py                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  STEP 2: Multi-Turn Parameter Gathering                                   â”‚ â”‚
â”‚  â”‚  Orchestrator: "What team will use this workspace?"                       â”‚ â”‚
â”‚  â”‚  Orchestrator: "What environment (dev/staging/prod)?"                     â”‚ â”‚
â”‚  â”‚  Orchestrator: "Which Azure region?"                                      â”‚ â”‚
â”‚  â”‚  â†“                                                                         â”‚ â”‚
â”‚  â”‚  User: "team=data-analytics-demo1, env=dev, region=eastus"               â”‚ â”‚
â”‚  â”‚  â†“                                                                         â”‚ â”‚
â”‚  â”‚  LLM extracts ALL parameters from single message:                         â”‚ â”‚
â”‚  â”‚    â€¢ team: "data-analytics-demo1"                                         â”‚ â”‚
â”‚  â”‚    â€¢ environment: "dev"                                                   â”‚ â”‚
â”‚  â”‚    â€¢ region: "eastus"                                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  STEP 3: Generate Naming Suggestions                                      â”‚ â”‚
â”‚  â”‚  Calls Tool: suggest_naming(                                              â”‚ â”‚
â”‚  â”‚      team="data-analytics-demo1",                                         â”‚ â”‚
â”‚  â”‚      environment="dev",                                                   â”‚ â”‚
â”‚  â”‚      resource_type="databricks"                                           â”‚ â”‚
â”‚  â”‚  )                                                                         â”‚ â”‚
â”‚  â”‚  â†“                                                                         â”‚ â”‚
â”‚  â”‚  Returns: {                                                                â”‚ â”‚
â”‚  â”‚    primary: "data-analytics-demo1-dev",                                   â”‚ â”‚
â”‚  â”‚    alternatives: [                                                        â”‚ â”‚
â”‚  â”‚      "dbw-data-analytics-demo1-dev",                                      â”‚ â”‚
â”‚  â”‚      "data-analytics-demo1-databricks-dev"                                â”‚ â”‚
â”‚  â”‚    ]                                                                       â”‚ â”‚
â”‚  â”‚  }                                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  STEP 4: Estimate Costs                                                   â”‚ â”‚
â”‚  â”‚  Calls Tool: estimate_cost(                                               â”‚ â”‚
â”‚  â”‚      capability="provision_databricks",                                   â”‚ â”‚
â”‚  â”‚      parameters={                                                         â”‚ â”‚
â”‚  â”‚        team: "data-analytics-demo1",                                      â”‚ â”‚
â”‚  â”‚        environment: "dev",                                                â”‚ â”‚
â”‚  â”‚        region: "eastus",                                                  â”‚ â”‚
â”‚  â”‚        workload_type: "data_engineering"                                  â”‚ â”‚
â”‚  â”‚      }                                                                     â”‚ â”‚
â”‚  â”‚  )                                                                         â”‚ â”‚
â”‚  â”‚  â†“                                                                         â”‚ â”‚
â”‚  â”‚  Returns: {                                                                â”‚ â”‚
â”‚  â”‚    monthly_estimate: 834.0,                                               â”‚ â”‚
â”‚  â”‚    breakdown: [                                                           â”‚ â”‚
â”‚  â”‚      {item: "Databricks Workspace", cost: 0},                             â”‚ â”‚
â”‚  â”‚      {item: "Standard Cluster", cost: 784},                               â”‚ â”‚
â”‚  â”‚      {item: "Azure Storage", cost: 50}                                    â”‚ â”‚
â”‚  â”‚    ],                                                                      â”‚ â”‚
â”‚  â”‚    currency: "USD",                                                       â”‚ â”‚
â”‚  â”‚    confidence: "medium"                                                   â”‚ â”‚
â”‚  â”‚  }                                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  STEP 5: Present Plan & Get Approval                                      â”‚ â”‚
â”‚  â”‚  Orchestrator presents:                                                   â”‚ â”‚
â”‚  â”‚    â€¢ Workspace name: "data-analytics-demo1-dev"                           â”‚ â”‚
â”‚  â”‚    â€¢ Monthly cost: $834                                                   â”‚ â”‚
â”‚  â”‚    â€¢ Resource breakdown                                                   â”‚ â”‚
â”‚  â”‚  â†“                                                                         â”‚ â”‚
â”‚  â”‚  User: "go ahead" â† Approval trigger phrase                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  STEP 6: Execute Deployment                                               â”‚ â”‚
â”‚  â”‚  Calls Tool: execute_deployment(                                          â”‚ â”‚
â”‚  â”‚      capability_name="provision_databricks",                              â”‚ â”‚
â”‚  â”‚      parameters={                                                         â”‚ â”‚
â”‚  â”‚        team: "data-analytics-demo1",                                      â”‚ â”‚
â”‚  â”‚        environment: "dev",                                                â”‚ â”‚
â”‚  â”‚        region: "eastus"                                                   â”‚ â”‚
â”‚  â”‚      }                                                                     â”‚ â”‚
â”‚  â”‚  )                                                                         â”‚ â”‚
â”‚  â”‚  File: orchestrator/tools.py                                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âš™ï¸ execute_deployment Tool                                                      â”‚
â”‚  File: orchestrator/tools.py (lines 21-68)                                      â”‚
â”‚                                                                                  â”‚
â”‚  Calls: await orchestrator.execute_capability(                                  â”‚
â”‚      capability_name="provision_databricks",                                    â”‚
â”‚      user_request="Deploy infrastructure",                                      â”‚
â”‚      parameters={team, environment, region, ...}                                â”‚
â”‚  )                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸŽ¯ orchestrator.execute_capability()                                           â”‚
â”‚  File: orchestrator/orchestrator_agent.py (lines 250-300)                      â”‚
â”‚                                                                                  â”‚
â”‚  Step 1: Build Context                                                          â”‚
â”‚  context = CapabilityContext(                                                   â”‚
â”‚      capability_name="provision_databricks",                                    â”‚
â”‚      user_request="Deploy infrastructure",                                      â”‚
â”‚      parameters={team, environment, region, ...}                                â”‚
â”‚  )                                                                               â”‚
â”‚                                                                                  â”‚
â”‚  Step 2: Execute Capability Lifecycle                                           â”‚
â”‚  â”œâ”€ plan = await capability.plan(context)         â† Generate deployment plan    â”‚
â”‚  â””â”€ result = await capability.execute(plan)       â† Deploy infrastructure       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ”§ DATABRICKS CAPABILITY - plan() Method                                       â”‚
â”‚  File: capabilities/databricks/capability.py (lines 71-150)                     â”‚
â”‚                                                                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“  â”‚
â”‚  â”ƒ  STEP 1: Build InfrastructureRequest                                    â”ƒ  â”‚
â”‚  â”ƒ  Method: _build_infrastructure_request(context)                         â”ƒ  â”‚
â”‚  â”ƒ  File: capabilities/databricks/capability.py (lines 255-290)            â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  âœ¨ OPTIMIZATION (November 10, 2025):                                    â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  required_params = self.get_required_parameters()                       â”ƒ  â”‚
â”‚  â”ƒ  # Returns: ["team", "environment", "region"]                           â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  has_all_required = all(param in context.parameters for param in ...)   â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  IF all required params present:                                        â”ƒ  â”‚
â”‚  â”ƒ     âœ… SKIP EXPENSIVE LLM CALL (Save cost + latency)                     â”ƒ  â”‚
â”‚  â”ƒ     âœ… Build directly from parameters                                    â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ     team = context.parameters["team"]                                   â”ƒ  â”‚
â”‚  â”ƒ     environment = context.parameters["environment"]                     â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ     # Auto-generate workspace name                                      â”ƒ  â”‚
â”‚  â”ƒ     workspace_name = context.parameters.get("workspace_name")           â”ƒ  â”‚
â”‚  â”ƒ     if not workspace_name:                                              â”ƒ  â”‚
â”‚  â”ƒ         workspace_name = f"{team}-{environment}"                        â”ƒ  â”‚
â”‚  â”ƒ         # "data-analytics-demo1-dev"                                    â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ     infra_request = InfrastructureRequest(                              â”ƒ  â”‚
â”‚  â”ƒ         team="data-analytics-demo1",                                    â”ƒ  â”‚
â”‚  â”ƒ         environment="dev",                                              â”ƒ  â”‚
â”‚  â”ƒ         region="eastus",                                                â”ƒ  â”‚
â”‚  â”ƒ         workspace_name="data-analytics-demo1-dev",  â† Auto-generated!   â”ƒ  â”‚
â”‚  â”ƒ         enable_gpu=False,                                               â”ƒ  â”‚
â”‚  â”ƒ         workload_type="data_engineering"                                â”ƒ  â”‚
â”‚  â”ƒ     )                                                                    â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  ELSE (missing params):                                                 â”ƒ  â”‚
â”‚  â”ƒ     âŒ Fallback to IntentParser (Azure OpenAI GPT-4o call)              â”ƒ  â”‚
â”‚  â”ƒ     File: capabilities/databricks/core/intent_parser.py                 â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ     request_text = self._build_request_text(context)                    â”ƒ  â”‚
â”‚  â”ƒ     infra_request = self.intent_parser.recognize_intent(request_text)   â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ     # Uses Azure OpenAI function calling to extract:                    â”ƒ  â”‚
â”‚  â”ƒ     # team, environment, region, workload_type, enable_gpu              â”ƒ  â”‚
â”‚  â”ƒ     # Auto-generates workspace_name if not provided                     â”ƒ  â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›  â”‚
â”‚                                                                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“  â”‚
â”‚  â”ƒ  STEP 2: Make Configuration Decisions                                   â”ƒ  â”‚
â”‚  â”ƒ  Component: DecisionMaker                                               â”ƒ  â”‚
â”‚  â”ƒ  File: capabilities/databricks/core/decision_maker.py                   â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  decision = self.decision_maker.make_decision(infra_request)            â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  Logic:                                                                  â”ƒ  â”‚
â”‚  â”ƒ  â”œâ”€ Determine workload size: small/medium/large                         â”ƒ  â”‚
â”‚  â”ƒ  â”‚    Based on: workload_type, environment                              â”ƒ  â”‚
â”‚  â”ƒ  â”‚                                                                       â”ƒ  â”‚
â”‚  â”ƒ  â”œâ”€ Select instance types:                                              â”ƒ  â”‚
â”‚  â”ƒ  â”‚    enable_gpu=False â†’ Standard_DS3_v2 (4 vCPU, 14GB RAM)            â”ƒ  â”‚
â”‚  â”ƒ  â”‚    enable_gpu=True  â†’ Standard_NC6s_v3 (6 vCPU, 112GB RAM, V100)    â”ƒ  â”‚
â”‚  â”ƒ  â”‚                                                                       â”ƒ  â”‚
â”‚  â”ƒ  â”œâ”€ Choose Databricks SKU:                                              â”ƒ  â”‚
â”‚  â”ƒ  â”‚    dev â†’ standard, staging â†’ standard, prod â†’ premium                â”ƒ  â”‚
â”‚  â”ƒ  â”‚                                                                       â”ƒ  â”‚
â”‚  â”ƒ  â”œâ”€ Configure cluster autoscaling:                                      â”ƒ  â”‚
â”‚  â”ƒ  â”‚    dev: min_workers=1, max_workers=3                                 â”ƒ  â”‚
â”‚  â”ƒ  â”‚    staging: min_workers=2, max_workers=5                             â”ƒ  â”‚
â”‚  â”ƒ  â”‚    prod: min_workers=3, max_workers=10                               â”ƒ  â”‚
â”‚  â”ƒ  â”‚                                                                       â”ƒ  â”‚
â”‚  â”ƒ  â”œâ”€ Select Spark version:                                               â”ƒ  â”‚
â”‚  â”ƒ  â”‚    GPU: 13.3.x-gpu-ml-scala2.12                                      â”ƒ  â”‚
â”‚  â”ƒ  â”‚    CPU: 13.3.x-scala2.12                                             â”ƒ  â”‚
â”‚  â”ƒ  â”‚                                                                       â”ƒ  â”‚
â”‚  â”ƒ  â””â”€ Estimate monthly costs:                                             â”ƒ  â”‚
â”‚  â”ƒ       Workspace base fee: $0 (no charge for standard)                   â”ƒ  â”‚
â”‚  â”ƒ       Compute: instance_cost Ã— avg_workers Ã— hours_per_month            â”ƒ  â”‚
â”‚  â”ƒ       Storage: $50 for ~500GB                                           â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  Result: InfrastructureDecision(                                        â”ƒ  â”‚
â”‚  â”ƒ      workspace_name="data-analytics-demo1-dev",                         â”ƒ  â”‚
â”‚  â”ƒ      resource_group_name="rg-data-analytics-demo1-dev",                 â”ƒ  â”‚
â”‚  â”ƒ      region="eastus",                                                   â”ƒ  â”‚
â”‚  â”ƒ      databricks_sku="standard",                                         â”ƒ  â”‚
â”‚  â”ƒ      driver_instance_type="Standard_DS3_v2",                            â”ƒ  â”‚
â”‚  â”ƒ      worker_instance_type="Standard_DS3_v2",                            â”ƒ  â”‚
â”‚  â”ƒ      min_workers=1,                                                     â”ƒ  â”‚
â”‚  â”ƒ      max_workers=3,                                                     â”ƒ  â”‚
â”‚  â”ƒ      spark_version="13.3.x-scala2.12",                                  â”ƒ  â”‚
â”‚  â”ƒ      autotermination_minutes=120,                                       â”ƒ  â”‚
â”‚  â”ƒ      estimated_monthly_cost=834.0                                       â”ƒ  â”‚
â”‚  â”ƒ  )                                                                       â”ƒ  â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›  â”‚
â”‚                                                                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“  â”‚
â”‚  â”ƒ  STEP 3: Generate Terraform HCL                                         â”ƒ  â”‚
â”‚  â”ƒ  Component: TerraformGenerator                                          â”ƒ  â”‚
â”‚  â”ƒ  File: capabilities/databricks/provisioning/terraform/generator.py      â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  terraform_files = self.terraform_generator.generate(decision)          â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  Process:                                                                â”ƒ  â”‚
â”‚  â”ƒ  â”œâ”€ Load Jinja2 templates from:                                         â”ƒ  â”‚
â”‚  â”ƒ  â”‚    capabilities/databricks/templates/                                â”ƒ  â”‚
â”‚  â”ƒ  â”‚    â”œâ”€ main.tf.j2 (resource definitions)                              â”ƒ  â”‚
â”‚  â”ƒ  â”‚    â”œâ”€ variables.tf.j2 (input variables)                              â”ƒ  â”‚
â”‚  â”ƒ  â”‚    â”œâ”€ outputs.tf.j2 (output values)                                  â”ƒ  â”‚
â”‚  â”ƒ  â”‚    â”œâ”€ provider.tf.j2 (azurerm, databricks providers)                 â”ƒ  â”‚
â”‚  â”ƒ  â”‚    â””â”€ terraform.tfvars.j2 (variable values)                          â”ƒ  â”‚
â”‚  â”ƒ  â”‚                                                                       â”ƒ  â”‚
â”‚  â”ƒ  â””â”€ Render each template with decision context                          â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  Result: TerraformFiles(                                                â”ƒ  â”‚
â”‚  â”ƒ      main_tf="""                                                         â”ƒ  â”‚
â”‚  â”ƒ        resource "azurerm_resource_group" "main" {                       â”ƒ  â”‚
â”‚  â”ƒ          name     = "rg-data-analytics-demo1-dev"                       â”ƒ  â”‚
â”‚  â”ƒ          location = "eastus"                                            â”ƒ  â”‚
â”‚  â”ƒ        }                                                                 â”ƒ  â”‚
â”‚  â”ƒ        resource "azurerm_databricks_workspace" "main" {                 â”ƒ  â”‚
â”‚  â”ƒ          name                = "data-analytics-demo1-dev"               â”ƒ  â”‚
â”‚  â”ƒ          resource_group_name = azurerm_resource_group.main.name         â”ƒ  â”‚
â”‚  â”ƒ          location            = azurerm_resource_group.main.location     â”ƒ  â”‚
â”‚  â”ƒ          sku                 = "standard"                               â”ƒ  â”‚
â”‚  â”ƒ        }                                                                 â”ƒ  â”‚
â”‚  â”ƒ      """,                                                                â”ƒ  â”‚
â”‚  â”ƒ      variables_tf="""...""",                                            â”ƒ  â”‚
â”‚  â”ƒ      outputs_tf="""...""",                                              â”ƒ  â”‚
â”‚  â”ƒ      ...                                                                 â”ƒ  â”‚
â”‚  â”ƒ  )                                                                       â”ƒ  â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›  â”‚
â”‚                                                                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“  â”‚
â”‚  â”ƒ  STEP 4: Terraform Plan (Dry-Run Preview)                               â”ƒ  â”‚
â”‚  â”ƒ  Component: TerraformExecutor                                           â”ƒ  â”‚
â”‚  â”ƒ  File: capabilities/databricks/provisioning/terraform/executor.py       â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  working_dir = "terraform_workspaces/data-analytics-demo1-dev_plan"     â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  plan_result = self.terraform_executor.execute_deployment(              â”ƒ  â”‚
â”‚  â”ƒ      terraform_files=terraform_files,                                   â”ƒ  â”‚
â”‚  â”ƒ      working_dir=working_dir,                                           â”ƒ  â”‚
â”‚  â”ƒ      auto_approve=False,                                                â”ƒ  â”‚
â”‚  â”ƒ      dry_run=True  â† Plan only, don't apply                             â”ƒ  â”‚
â”‚  â”ƒ  )                                                                       â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  Execution:                                                              â”ƒ  â”‚
â”‚  â”ƒ  â”œâ”€ Write all 5 files to working_dir                                    â”ƒ  â”‚
â”‚  â”ƒ  â”œâ”€ Run: terraform init                                                 â”ƒ  â”‚
â”‚  â”ƒ  â”‚    Downloads providers: azurerm, databricks                          â”ƒ  â”‚
â”‚  â”ƒ  â”œâ”€ Run: terraform plan -out=tfplan                                     â”ƒ  â”‚
â”‚  â”ƒ  â”‚    Preview: 3 resources to create                                    â”ƒ  â”‚
â”‚  â”ƒ  â”‚      + azurerm_resource_group.main                                   â”ƒ  â”‚
â”‚  â”ƒ  â”‚      + azurerm_databricks_workspace.main                             â”ƒ  â”‚
â”‚  â”ƒ  â”‚      + databricks_cluster.main                                       â”ƒ  â”‚
â”‚  â”ƒ  â””â”€ Parse plan output and return preview                                â”ƒ  â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›  â”‚
â”‚                                                                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“  â”‚
â”‚  â”ƒ  STEP 5: Return CapabilityPlan                                          â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  Return: CapabilityPlan(                                                â”ƒ  â”‚
â”‚  â”ƒ      capability_name="provision_databricks",                            â”ƒ  â”‚
â”‚  â”ƒ      description="Provision Databricks workspace for ...",              â”ƒ  â”‚
â”‚  â”ƒ      resources=[                                                        â”ƒ  â”‚
â”‚  â”ƒ        {type: "Resource Group", name: "rg-data-analytics-demo1-dev"},   â”ƒ  â”‚
â”‚  â”ƒ        {type: "Databricks Workspace", name: "data-analytics-demo1-dev"},â”ƒ  â”‚
â”‚  â”ƒ        {type: "Databricks Cluster", name: "...-cluster"}                â”ƒ  â”‚
â”‚  â”ƒ      ],                                                                  â”ƒ  â”‚
â”‚  â”ƒ      estimated_cost=834.0,                                              â”ƒ  â”‚
â”‚  â”ƒ      estimated_duration=15,  # minutes                                  â”ƒ  â”‚
â”‚  â”ƒ      requires_approval=True,                                            â”ƒ  â”‚
â”‚  â”ƒ      details={                                                           â”ƒ  â”‚
â”‚  â”ƒ        decision: InfrastructureDecision(...),                           â”ƒ  â”‚
â”‚  â”ƒ        terraform_files: TerraformFiles(...),                            â”ƒ  â”‚
â”‚  â”ƒ        terraform_plan: "Plan output...",                                â”ƒ  â”‚
â”‚  â”ƒ        working_dir: "terraform_workspaces/..."                          â”ƒ  â”‚
â”‚  â”ƒ      }                                                                   â”ƒ  â”‚
â”‚  â”ƒ  )                                                                       â”ƒ  â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ Plan approved by user
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸš€ DATABRICKS CAPABILITY - execute() Method                                    â”‚
â”‚  File: capabilities/databricks/capability.py (lines 152-235)                    â”‚
â”‚                                                                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“  â”‚
â”‚  â”ƒ  STEP 1: Reconstruct Context from Plan                                  â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  working_dir = Path(plan.details["working_dir"])                        â”ƒ  â”‚
â”‚  â”ƒ  terraform_files_data = plan.details["terraform_files"]                 â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  terraform_files = TerraformFiles(                                      â”ƒ  â”‚
â”‚  â”ƒ      main_tf=terraform_files_data["main.tf"],                           â”ƒ  â”‚
â”‚  â”ƒ      variables_tf=terraform_files_data["variables.tf"],                 â”ƒ  â”‚
â”‚  â”ƒ      outputs_tf=terraform_files_data["outputs.tf"],                     â”ƒ  â”‚
â”‚  â”ƒ      ...                                                                 â”ƒ  â”‚
â”‚  â”ƒ  )                                                                       â”ƒ  â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›  â”‚
â”‚                                                                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“  â”‚
â”‚  â”ƒ  STEP 2: Terraform Apply (ACTUAL DEPLOYMENT!)                           â”ƒ  â”‚
â”‚  â”ƒ  Component: TerraformExecutor                                           â”ƒ  â”‚
â”‚  â”ƒ  File: capabilities/databricks/provisioning/terraform/executor.py       â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  result = self.terraform_executor.execute_deployment(                   â”ƒ  â”‚
â”‚  â”ƒ      terraform_files=terraform_files,                                   â”ƒ  â”‚
â”‚  â”ƒ      working_dir=working_dir,                                           â”ƒ  â”‚
â”‚  â”ƒ      auto_approve=True,  â† User already approved in plan phase          â”ƒ  â”‚
â”‚  â”ƒ      dry_run=False  â† Actually deploy to Azure!                         â”ƒ  â”‚
â”‚  â”ƒ  )                                                                       â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  Execution Timeline (~13 minutes):                                      â”ƒ  â”‚
â”‚  â”ƒ  00:00 - Run: terraform apply -auto-approve tfplan                      â”ƒ  â”‚
â”‚  â”ƒ  00:30 - Creating Resource Group                                        â”ƒ  â”‚
â”‚  â”ƒ  02:00 - Creating Databricks Workspace                                  â”ƒ  â”‚
â”‚  â”ƒ  08:00 - Configuring managed resource group                             â”ƒ  â”‚
â”‚  â”ƒ  10:00 - Creating Databricks Cluster                                    â”ƒ  â”‚
â”‚  â”ƒ  12:30 - Cluster starting...                                            â”ƒ  â”‚
â”‚  â”ƒ  13:00 - âœ… Deployment complete!                                         â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  Post-Deployment:                                                        â”ƒ  â”‚
â”‚  â”ƒ  â””â”€ Run: terraform output -json                                         â”ƒ  â”‚
â”‚  â”ƒ       Parse outputs:                                                    â”ƒ  â”‚
â”‚  â”ƒ       â€¢ workspace_url: "https://adb-123456.azuredatabricks.net"         â”ƒ  â”‚
â”‚  â”ƒ       â€¢ workspace_id: "123456789"                                       â”ƒ  â”‚
â”‚  â”ƒ       â€¢ resource_group: "rg-data-analytics-demo1-dev"                   â”ƒ  â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›  â”‚
â”‚                                                                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“  â”‚
â”‚  â”ƒ  STEP 3: Return CapabilityResult                                        â”ƒ  â”‚
â”‚  â”ƒ                                                                          â”ƒ  â”‚
â”‚  â”ƒ  Return: CapabilityResult(                                              â”ƒ  â”‚
â”‚  â”ƒ      capability_name="provision_databricks",                            â”ƒ  â”‚
â”‚  â”ƒ      success=True,                                                      â”ƒ  â”‚
â”‚  â”ƒ      message="Successfully deployed Databricks workspace",              â”ƒ  â”‚
â”‚  â”ƒ      resources_created=[                                                â”ƒ  â”‚
â”‚  â”ƒ        {type: "Resource Group", ...},                                   â”ƒ  â”‚
â”‚  â”ƒ        {type: "Databricks Workspace", ...},                             â”ƒ  â”‚
â”‚  â”ƒ        {type: "Databricks Cluster", ...}                                â”ƒ  â”‚
â”‚  â”ƒ      ],                                                                  â”ƒ  â”‚
â”‚  â”ƒ      outputs={                                                           â”ƒ  â”‚
â”‚  â”ƒ        "workspace_url": "https://adb-123456.azuredatabricks.net",       â”ƒ  â”‚
â”‚  â”ƒ        "workspace_id": "123456789",                                     â”ƒ  â”‚
â”‚  â”ƒ        "resource_group": "rg-data-analytics-demo1-dev"                  â”ƒ  â”‚
â”‚  â”ƒ      },                                                                  â”ƒ  â”‚
â”‚  â”ƒ      duration_seconds=780  # ~13 minutes                                â”ƒ  â”‚
â”‚  â”ƒ  )                                                                       â”ƒ  â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â˜ï¸ AZURE RESOURCES - Deployed & Running                                        â”‚
â”‚                                                                                  â”‚
â”‚  âœ… Resource Group: rg-data-analytics-demo1-dev                                 â”‚
â”‚     â€¢ Location: East US                                                         â”‚
â”‚     â€¢ Tags: {team: "data-analytics-demo1", env: "dev"}                          â”‚
â”‚                                                                                  â”‚
â”‚  âœ… Databricks Workspace: data-analytics-demo1-dev                              â”‚
â”‚     â€¢ SKU: Standard                                                             â”‚
â”‚     â€¢ URL: https://adb-123456789.azuredatabricks.net                            â”‚
â”‚     â€¢ Managed Resource Group: databricks-rg-...                                 â”‚
â”‚     â€¢ Public Network Access: Enabled                                            â”‚
â”‚                                                                                  â”‚
â”‚  âœ… Databricks Cluster: data-analytics-demo1-dev-cluster                        â”‚
â”‚     â€¢ Driver Node: Standard_DS3_v2                                              â”‚
â”‚     â€¢   - 4 vCPU, 14 GB RAM                                                     â”‚
â”‚     â€¢ Worker Nodes: 1-3 autoscaling (Standard_DS3_v2)                           â”‚
â”‚     â€¢   - Each: 4 vCPU, 14 GB RAM                                               â”‚
â”‚     â€¢ Spark Version: 13.3.x-scala2.12                                           â”‚
â”‚     â€¢ Autotermination: 120 minutes idle                                         â”‚
â”‚     â€¢ Status: RUNNING ðŸŸ¢                                                        â”‚
â”‚                                                                                  â”‚
â”‚  âœ… Azure Storage Account: dbstorage (managed by Databricks)                    â”‚
â”‚     â€¢ Blob Storage: ~500GB capacity                                             â”‚
â”‚     â€¢ Replication: LRS (Locally Redundant Storage)                              â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ðŸ“Š COST BREAKDOWN                                                       â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚  Databricks Workspace Base Fee:          $0.00/month                    â”‚   â”‚
â”‚  â”‚  Compute Cluster (Standard_DS3_v2):   $784.00/month                     â”‚   â”‚
â”‚  â”‚    â€¢ ~40 hours/week usage                                                â”‚   â”‚
â”‚  â”‚    â€¢ 1-3 workers autoscaling                                             â”‚   â”‚
â”‚  â”‚  Azure Blob Storage (~500GB):           $50.00/month                     â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚  TOTAL ESTIMATED MONTHLY COST:        $834.00/month                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                  â”‚
â”‚  â±ï¸ Total Deployment Time: ~13 minutes                                          â”‚
â”‚  ðŸŽ¯ Status: Ready for Data Analytics Workloads! ðŸš€                              â”‚
â”‚                                                                                  â”‚
â”‚  Next Steps for User:                                                           â”‚
â”‚  1. Visit: https://adb-123456789.azuredatabricks.net                            â”‚
â”‚  2. Sign in with Azure credentials                                              â”‚
â”‚  3. Create notebooks and start analyzing data                                   â”‚
â”‚  4. Cluster will auto-terminate after 120 min of inactivity                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ¯ Key Optimizations (November 10, 2025)

### 1. **LLM Call Optimization** (Cost & Latency Savings)
**Location**: `capabilities/databricks/capability.py::_build_infrastructure_request()`

**Before**:
```python
# Always called IntentParser (Azure OpenAI GPT-4o)
infra_request = self.intent_parser.recognize_intent(request_text)
# Cost: ~$0.01 per call, Latency: ~1-2 seconds
```

**After**:
```python
required_params = self.get_required_parameters()  # ["team", "environment", "region"]
has_all_required = all(param in context.parameters for param in required_params)

if has_all_required:
    # âœ… Skip LLM call - build directly from parameters
    workspace_name = f"{team}-{environment}"  # Auto-generate
    infra_request = InfrastructureRequest(...)
else:
    # âŒ Fallback to LLM only when needed
    infra_request = self.intent_parser.recognize_intent(request_text)
```

**Benefits**:
- âœ… Saves ~$0.01 per deployment when all params present
- âœ… Reduces latency by 1-2 seconds
- âœ… More predictable behavior
- âœ… Matches IntentParser name generation logic

### 2. **Single Source of Truth** (DRY Principle)
**Location**: `capabilities/databricks/capability.py`

**Before**: Required params hardcoded in 3 places
```python
# In _build_infrastructure_request():
required_params = ["team", "environment", "region"]

# In _build_request_text():
if "team" in context.parameters: ...
if "environment" in context.parameters: ...
if "region" in context.parameters: ...

# In get_required_parameters():
return ["team", "environment", "region"]
```

**After**: Single source of truth
```python
# Define once:
def get_required_parameters(self) -> list[str]:
    return ["team", "environment", "region"]

# Use everywhere:
required_params = self.get_required_parameters()
for param in self.get_required_parameters():
    ...
```

**Benefits**:
- âœ… Change once, updates everywhere
- âœ… Eliminates copy-paste errors
- âœ… Easier to maintain

### 3. **Bug Fix: Workspace Name Generation**
**Location**: `capabilities/databricks/capability.py::_build_infrastructure_request()`

**Problem**: When bypassing IntentParser, workspace_name was empty string `""`, causing Terraform error:
```
Error: "name" cannot be an empty string: ""
```

**Solution**: Auto-generate workspace_name matching IntentParser behavior:
```python
workspace_name = context.parameters.get("workspace_name")
if not workspace_name:
    workspace_name = f"{team}-{environment}"
    # "data-analytics-demo1-dev"
```

**Benefits**:
- âœ… Terraform validation passes
- âœ… Consistent naming convention
- âœ… Works with or without IntentParser

---

## ðŸ“Š Performance Metrics

| Metric | Value | Notes |
|--------|-------|-------|
| **Total Deployment Time** | ~13 minutes | terraform init + plan + apply |
| **LLM Calls (Optimized Path)** | 5-6 calls | Orchestrator conversation + tools |
| **LLM Calls (Non-Optimized)** | 6-7 calls | +1 for IntentParser |
| **Cost per Deployment** | ~$0.05-0.10 | Azure OpenAI GPT-4o token usage |
| **Infrastructure Cost** | $834/month | Workspace + compute + storage |
| **Test Coverage** | 94/94 tests passing | 100% success rate |

---

## ðŸ”‘ Key Files Reference

| Component | File Path | Lines | Purpose |
|-----------|-----------|-------|---------|
| **CLI Entry** | `cli_maf.py` | 69 | User interaction loop |
| **Orchestrator** | `orchestrator/orchestrator_agent.py` | 359 | MAF agent, conversation mgmt |
| **Tool Manager** | `orchestrator/tool_manager.py` | 253 | Dynamic tool registration |
| **Tools** | `orchestrator/tools.py` | 280 | 4 tools (select, suggest, estimate, execute) |
| **Capability Registry** | `orchestrator/capability_registry.py` | - | Anti-hallucination validation |
| **Databricks Capability** | `capabilities/databricks/capability.py` | 366 | Main capability implementation |
| **Intent Parser** | `capabilities/databricks/core/intent_parser.py` | - | NL â†’ InfrastructureRequest |
| **Decision Maker** | `capabilities/databricks/core/decision_maker.py` | 246 | Config decisions + cost estimation |
| **Terraform Generator** | `capabilities/databricks/provisioning/terraform/generator.py` | - | Jinja2 â†’ HCL |
| **Terraform Executor** | `capabilities/databricks/provisioning/terraform/executor.py` | - | Terraform subprocess mgmt |
| **Data Models** | `capabilities/databricks/models/schemas.py` | 188 | Pydantic schemas |
| **Config** | `capabilities/databricks/core/config.py` | - | Instance types, pricing, regions |

---

**Last Updated**: November 10, 2025
**Status**: Production-Ready with Optimizations
**Test Coverage**: 94/94 tests (100%)
**Deployment Success Rate**: âœ… Verified in Azure
